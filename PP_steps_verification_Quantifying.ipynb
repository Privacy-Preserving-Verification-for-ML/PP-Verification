{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d81fb3-dcfe-4505-9c2a-1a2a710de2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from preprocessing_pipeline_Quantifying import PreprocessingPipeline\n",
    "from explanation_collection import explanation_collection\n",
    "from differential_privacy import DifferentialPrivacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f565223d-8bcd-4c22-acb5-5cdf31ac4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = int(os.environ.get('DATASET_ID'))\n",
    "numerical_columns = os.environ.get('NUMERICAL_COLUMNS')\n",
    "numerical_columns = [item.strip() for item in numerical_columns.split(',')]\n",
    "case_id = int(os.environ.get('CASE_ID'))\n",
    "epsilon = int(os.environ.get('EPSILON'))\n",
    "rep = int(os.environ.get('REPEAT'))\n",
    "\n",
    "path = os.environ.get('OUTPUT_DIRECTORY')\n",
    "\n",
    "# dataset_id = 891\n",
    "# numerical_columns = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "# case_id = 0\n",
    "# epsilon = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4003ca25-a9f8-4e4a-9502-8f44470a0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "uci_dataset = fetch_ucirepo(id=dataset_id)\n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = uci_dataset.data.features \n",
    "y = uci_dataset.data.targets \n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "target_col = y.columns[0]\n",
    "\n",
    "# Select the remaining columns as categorical columns\n",
    "all_columns = set(X.columns)\n",
    "categorical_columns = list(all_columns - set(numerical_columns))\n",
    "\n",
    "pipeline = PreprocessingPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232e445d-9538-41c9-bdf2-f51f1b88253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Dropped: 0 rows removed\n",
      "Percentage of rows dropped due to missing values: 0.00%\n",
      "number of categorical columns '14\n"
     ]
    }
   ],
   "source": [
    "steps_prior = [\n",
    "    'drop_missing_values',\n",
    "\n",
    "    'encode_categorical_variables',\n",
    "]\n",
    "\n",
    "X, y = pipeline.preprocess(data, target_col, numerical_columns, categorical_columns, steps_prior)\n",
    "\n",
    "if dataset_id == 2:\n",
    "    y = np.where((y == 0) | (y == 1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0c0404-fb17-4889-a103-15cc5a98d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_o, X_q, y_o, y_q = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_o to a pandas Series\n",
    "y_o_series = pd.Series(y_o, name=target_col)\n",
    "y_q_series = pd.Series(y_q, name=target_col)\n",
    "\n",
    "# Reset index of X_o\n",
    "X_o = X_o.reset_index(drop=True)\n",
    "X_q = X_q.reset_index(drop=True)\n",
    "\n",
    "# Combine X and y into a single DataFrame\n",
    "df = pd.concat([X_o, y_o_series], axis=1)\n",
    "    \n",
    "df_q = pd.concat([X_q, y_q_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b93233-92d5-4e2c-934e-becbdf18d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DifferentialPrivacy(epsilon)\n",
    "\n",
    "df_r = df.copy()\n",
    "\n",
    "if epsilon != 0:\n",
    "    df_v = dp.apply_differential_privacy(df, numerical_columns, categorical_columns, round_to_int=True)\n",
    "else:\n",
    "    df_v = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881f4658-a33c-419d-b0dd-7d17a3a9cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination(case_id):\n",
    "    elements = [1, 2, 3, 4]\n",
    "    all_combinations = []\n",
    "\n",
    "    # Generate all non-empty combinations of the elements\n",
    "    for r in range(4, 0, -1):\n",
    "        all_combinations.extend(combinations(elements, r))\n",
    "\n",
    "    # Map the case_id to the corresponding combination\n",
    "    if 0 <= case_id < len(all_combinations):\n",
    "        return list(all_combinations[case_id])\n",
    "    else:\n",
    "        return \"Invalid case_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f57b95-cbdb-445d-ba8b-c3047ce12d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['drop_all_duplicates', 'handle_outliers', 'scale_numerical_features_only', 'resample_data']\n",
    "\n",
    "steps_in_r = get_combination(case_id)\n",
    "steps_in_v = get_combination(case_id)\n",
    "\n",
    "steps_r = [steps[i-1] for i in steps_in_r]\n",
    "steps_v = [steps[i-1] for i in steps_in_v]\n",
    "\n",
    "steps_qr = None\n",
    "steps_qv = None\n",
    "\n",
    "if 3 in steps_in_r:\n",
    "    steps_qr = [steps[2]]\n",
    "if 3 in steps_in_v:\n",
    "    steps_qv = [steps[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74345506-51a4-4c91-a50e-2beaaf604949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates Dropped: 17359 rows removed\n",
      "Percentage of rows dropped due to duplicates: 8.55%\n",
      "Outliers: 15233 rows removed\n",
      "Percentage of rows dropped due to outliers: 8.21%\n",
      "number of numerical columns '7\n",
      "Mean relative change for each feature:\n",
      " BMI          0.970887\n",
      "GenHlth      0.780531\n",
      "MentHlth     0.513143\n",
      "PhysHlth     0.599856\n",
      "Age          0.935646\n",
      "Education    0.858547\n",
      "Income       0.911513\n",
      "dtype: float64\n",
      "Overall mean relative change: 0.7957321294793795\n",
      "Percentage change in row count due to resampling: 71.44%\n",
      "Duplicates Dropped: 17359 rows removed\n",
      "Percentage of rows dropped due to duplicates: 8.55%\n",
      "Outliers: 15233 rows removed\n",
      "Percentage of rows dropped due to outliers: 8.21%\n",
      "number of numerical columns '7\n",
      "Mean relative change for each feature:\n",
      " BMI          0.970887\n",
      "GenHlth      0.780531\n",
      "MentHlth     0.513143\n",
      "PhysHlth     0.599856\n",
      "Age          0.935646\n",
      "Education    0.858547\n",
      "Income       0.911513\n",
      "dtype: float64\n",
      "Overall mean relative change: 0.7957321294793795\n",
      "Percentage change in row count due to resampling: 71.44%\n",
      "number of numerical columns '7\n",
      "number of numerical columns '7\n"
     ]
    }
   ],
   "source": [
    "# Apply the preprocessing pipeline\n",
    "if steps_r:\n",
    "    X_r, y_r = pipeline.preprocess(df_r, target_col, numerical_columns, categorical_columns, steps_r, train=True)\n",
    "else:\n",
    "    X_r, y_r = df.iloc[:,0:-1], df.iloc[:, -1]\n",
    "\n",
    "if steps_v:\n",
    "    X_v, y_v = pipeline.preprocess(df_v, target_col, numerical_columns, categorical_columns, steps_v, train=True)\n",
    "else:\n",
    "    X_v, y_v = df.iloc[:,0:-1], df.iloc[:, -1]\n",
    "\n",
    "# # For querying\n",
    "# if steps_qr:\n",
    "#     X_qr, y_qr = pipeline.preprocess(df_q, target_col, numerical_columns, categorical_columns, steps_qr, train=False, X_train=X_r)\n",
    "# else:\n",
    "#     X_qr, y_qr = df_q.iloc[:, 0:-1], df_q.iloc[:, -1]\n",
    "\n",
    "# if steps_qv:\n",
    "#     X_qv, y_qv = pipeline.preprocess(df_q, target_col, numerical_columns, categorical_columns, steps_qv, train=False, X_train=X_v)\n",
    "# else:\n",
    "#     X_qv, y_qv = df_q.iloc[:, 0:-1], df_q.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907e9d3-c73c-41c6-ba95-a788fbf4ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_r = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model_r.fit(X_r, y_r)\n",
    "# y_pred_r = model_v.predict(X_qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4c0c2-cd79-4b95-8dc0-7c161c1861ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model_v.fit(X_v, y_v)\n",
    "# y_pred_v = model_v.predict(X_qv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0952ffb-0082-4692-b553-a8ae1955df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(data1, data2):\n",
    "    if isinstance(data1, pd.DataFrame):\n",
    "        data1 = data1.values\n",
    "    if isinstance(data2, pd.DataFrame):\n",
    "        data2 = data2.values\n",
    "\n",
    "    rows1, cols1 = data1.shape\n",
    "    rows2, cols2 = data2.shape\n",
    "    \n",
    "    # Ensure both datasets have the same number of columns\n",
    "    if cols1 != cols2:\n",
    "        raise ValueError(\"Datasets must have the same number of columns\")\n",
    "\n",
    "    # Pad or truncate the datasets to have the same number of rows\n",
    "    if rows1 > rows2:\n",
    "        padding = np.zeros((rows1 - rows2, cols1))\n",
    "        data2 = np.vstack([data2, padding])\n",
    "    elif rows1 < rows2:\n",
    "        padding = np.zeros((rows2 - rows1, cols1))\n",
    "        data1 = np.vstack([data1, padding])\n",
    "    \n",
    "    return data1, data2\n",
    "\n",
    "def calculate_relative_euclidean_distance(data1, data2):\n",
    "    data1, data2 = pad_or_truncate(data1, data2)\n",
    "    vector1 = data1.flatten()\n",
    "    vector2 = data2.flatten()\n",
    "    euclidean_distance = np.linalg.norm(vector1 - vector2)\n",
    "    \n",
    "    max_possible_distance = np.linalg.norm(np.max(data1, axis=0) - np.min(data1, axis=0)) * np.sqrt(len(vector1))\n",
    "    relative_distance = euclidean_distance / max_possible_distance\n",
    "    \n",
    "    return relative_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f5924-d0db-4ee0-925b-d846dd1c398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accuracy\n",
    "# model_r_accuracy = accuracy_score(y_qr, y_pred_r)\n",
    "# model_v_accuracy = accuracy_score(y_qv, y_pred_v)\n",
    "\n",
    "# Row Metric\n",
    "row_metric_r = X_r.shape[0] / X_o.shape[0]\n",
    "row_metric_v = X_v.shape[0] / X_o.shape[0]\n",
    "\n",
    "relative_distance = calculate_relative_euclidean_distance(X_r, X_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b48698-082e-4784-a639-f2cafa42d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def compute_mmd(X_o, X_r, gamma=1.0):\n",
    "    K_oo = rbf_kernel(X_o, X_o, gamma=gamma)\n",
    "    K_rr = rbf_kernel(X_r, X_r, gamma=gamma)\n",
    "    K_or = rbf_kernel(X_o, X_r, gamma=gamma)\n",
    "\n",
    "    m = len(X_o)\n",
    "    n = len(X_r)\n",
    "\n",
    "    mmd_squared = (1/m**2) * np.sum(K_oo) + (1/n**2) * np.sum(K_rr) - (2/(m*n)) * np.sum(K_or)\n",
    "    return np.sqrt(mmd_squared)\n",
    "\n",
    "# Assuming X_o and X_r are your dataframes\n",
    "X_o_array = X_o.values\n",
    "X_r_array = X_r.values\n",
    "X_v_array = X_v.values\n",
    "\n",
    "batch_size = 1000\n",
    "if dataset_id == 45:\n",
    "    batch_size = 1\n",
    "    \n",
    "num_batches = len(X_o) // batch_size\n",
    "\n",
    "MMD_r = []\n",
    "MMD_v = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    X_o_batch = X_o.sample(n=batch_size, random_state=42).values\n",
    "    X_r_batch = X_r.sample(n=batch_size, random_state=42).values\n",
    "    X_v_batch = X_v.sample(n=batch_size, random_state=42).values\n",
    "\n",
    "    mmd_r = compute_mmd(X_o_batch, X_r_batch, gamma=1.0)\n",
    "    mmd_v = compute_mmd(X_o_batch, X_v_batch, gamma=1.0)\n",
    "\n",
    "    MMD_r.append(mmd_r)\n",
    "    MMD_v.append(mmd_v)\n",
    "\n",
    "\n",
    "overall_mmd_r = np.mean(MMD_r)\n",
    "overall_mmd_v = np.mean(MMD_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36586a-ada3-40b9-a433-aa13a714de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array([case_id, overall_mmd_r, row_metric_r, relative_distance]).reshape(1,-1)\n",
    "results_df = pd.DataFrame(results, columns= ['case_id', 'mmd', 'row_metric', 'relative_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c33586-92b6-4d3f-8fd1-42f09467bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'{path}/dataset{dataset_id}_eps{epsilon}_mmd_case{case_id}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe4379f-228b-4dc6-a6d2-e781adf0e454",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_explanations_r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m case_id\n\u001b[0;32m----> 2\u001b[0m df_explanations_r\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eps\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_resR_case\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m df_explanations_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m case_id\n\u001b[1;32m      5\u001b[0m df_explanations_v\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eps\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_resV_case\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# df_explanations_r['case'] = case_id\n",
    "# df_explanations_r.to_csv(f'{path}/dataset{dataset_id}_eps{epsilon}_resR_case{case_id}_rep{rep}.csv', index=False)\n",
    "\n",
    "# df_explanations_v['case'] = case_id\n",
    "# df_explanations_v.to_csv(f'{path}/dataset{dataset_id}_eps{epsilon}_resV_case{case_id}_rep{rep}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277b193-ce02-4e32-8511-0f00f3763e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
